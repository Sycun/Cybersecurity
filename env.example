# AI服务配置
AI_SERVICE=deepseek  # 可选值: deepseek, siliconflow, local, openai_compatible
DEFAULT_AI_MODEL=deepseek-chat  # 默认模型

# DeepSeek API配置
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions
DEEPSEEK_MODEL=deepseek-chat

# 硅基流动 API配置
SILICONFLOW_API_KEY=your_siliconflow_api_key_here
SILICONFLOW_API_URL=https://api.siliconflow.cn/v1/chat/completions
SILICONFLOW_MODEL=Qwen/QwQ-32B

# 本地AI模型配置
LOCAL_MODEL_PATH=/path/to/local/model  # 本地模型路径，例如: ./models/chatglm3-6b
LOCAL_MODEL_TYPE=auto  # 模型类型，通常设为auto自动检测
LOCAL_MODEL_DEVICE=auto  # 设备选择: auto, cpu, cuda
LOCAL_MODEL_MAX_LENGTH=4096  # 最大生成长度
LOCAL_MODEL_TEMPERATURE=0.7  # 生成温度

# OpenAI兼容API配置（支持本地部署的OpenAI API服务）
OPENAI_COMPATIBLE_API_KEY=sk-no-key-required  # API密钥，本地服务可能不需要
OPENAI_COMPATIBLE_API_URL=http://localhost:8000/v1/chat/completions  # API地址
OPENAI_COMPATIBLE_MODEL=gpt-3.5-turbo  # 模型名称

# 数据库配置
DATABASE_URL=sqlite:///./ctf_analyzer.db

# 服务器配置
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_PORT=3000

# 安全配置
SECRET_KEY=your_secret_key_here
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000 